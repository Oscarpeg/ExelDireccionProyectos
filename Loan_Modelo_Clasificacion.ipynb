{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelo Predictivo de Aprobación de Préstamos**\n",
    "## *Clasificación Supervisada con Pipelines para Evaluación de Riesgo Crediticio*\n",
    "\n",
    "---\n",
    "\n",
    "### **Introducción**\n",
    "\n",
    "La evaluación del riesgo crediticio es fundamental para las instituciones financieras. Determinar si un solicitante de préstamo cumplirá con sus obligaciones de pago es una decisión que involucra múltiples factores: perfil demográfico, historial crediticio, capacidad de pago y propósito del préstamo.\n",
    "\n",
    "Un modelo predictivo de clasificación puede ayudar a:\n",
    "- **Automatizar** la evaluación inicial de solicitudes\n",
    "- **Reducir** el riesgo de default\n",
    "- **Identificar** los factores más relevantes en la decisión\n",
    "- **Optimizar** la cartera de préstamos\n",
    "\n",
    "### **Objetivo del Estudio**\n",
    "\n",
    "Desarrollar un modelo de **clasificación binaria** que prediga si un préstamo será aprobado/pagado exitosamente (1) o rechazado/default (0), utilizando:\n",
    "\n",
    "1. **Pipelines de scikit-learn** para preprocesamiento y modelado\n",
    "2. **Múltiples algoritmos** de clasificación\n",
    "3. **Métricas de evaluación**: Precision, Recall, Accuracy, F1-Score, AUC-ROC\n",
    "\n",
    "### **Los Datos**\n",
    "\n",
    "El dataset contiene **45,000 solicitudes de préstamo** con las siguientes variables:\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| `person_age` | Edad del solicitante |\n",
    "| `person_gender` | Género |\n",
    "| `person_education` | Nivel educativo |\n",
    "| `person_income` | Ingresos anuales |\n",
    "| `person_emp_exp` | Años de experiencia laboral |\n",
    "| `person_home_ownership` | Tipo de vivienda |\n",
    "| `loan_amnt` | Monto del préstamo solicitado |\n",
    "| `loan_intent` | Propósito del préstamo |\n",
    "| `loan_int_rate` | Tasa de interés |\n",
    "| `loan_percent_income` | % del ingreso que representa el préstamo |\n",
    "| `cb_person_cred_hist_length` | Años de historial crediticio |\n",
    "| `credit_score` | Puntaje crediticio |\n",
    "| `previous_loan_defaults_on_file` | Defaults previos (Sí/No) |\n",
    "| **`loan_status`** | **Variable objetivo** (0=Default, 1=Pagado) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. Configuración del Entorno**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning y Pipelines\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, classification_report, confusion_matrix,\n",
    "                             roc_auc_score, roc_curve, precision_recall_curve)\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. Carga y Exploración de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde GitHub\n",
    "url = 'https://raw.githubusercontent.com/Oscarpeg/ExelDireccionProyectos/main/loan_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape[0]:,} filas × {df.shape[1]} columnas\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general\n",
    "print(\"=\"*60)\n",
    "print(\"INFORMACIÓN GENERAL DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDimensiones: {df.shape[0]:,} registros × {df.shape[1]} variables\")\n",
    "print(f\"\\nValores faltantes: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"=\"*60)\n",
    "print(\"ESTADÍSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\"*60)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de la variable objetivo\n",
    "print(\"=\"*60)\n",
    "print(\"DISTRIBUCIÓN DE LA VARIABLE OBJETIVO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Conteo\n",
    "counts = df['loan_status'].value_counts()\n",
    "labels = ['Rechazado/Default (0)', 'Aprobado/Pagado (1)']\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "\n",
    "axes[0].bar(labels, counts.values, color=colors)\n",
    "axes[0].set_title('Distribución de loan_status', fontweight='bold')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "for i, v in enumerate(counts.values):\n",
    "    axes[0].text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Porcentaje\n",
    "axes[1].pie(counts.values, labels=labels, autopct='%1.1f%%', colors=colors, explode=[0.02, 0.02])\n",
    "axes[1].set_title('Proporción de Clases', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClase 0 (Rechazado/Default): {counts[0]:,} ({counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Clase 1 (Aprobado/Pagado): {counts[1]:,} ({counts[1]/len(df)*100:.1f}%)\")\n",
    "print(f\"\\n⚠ NOTA: Dataset DESBALANCEADO - La clase minoritaria es solo {counts[1]/len(df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. Análisis Exploratorio de Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de variables numéricas vs loan_status\n",
    "num_vars = ['person_age', 'person_income', 'loan_amnt', 'loan_int_rate', \n",
    "            'loan_percent_income', 'credit_score']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(num_vars):\n",
    "    df.boxplot(column=var, by='loan_status', ax=axes[i])\n",
    "    axes[i].set_title(f'{var} por loan_status', fontweight='bold')\n",
    "    axes[i].set_xlabel('loan_status')\n",
    "    \n",
    "plt.suptitle('Variables Numéricas por Estado del Préstamo', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasa de aprobación por variables categóricas\n",
    "cat_vars = ['person_gender', 'person_education', 'person_home_ownership', \n",
    "            'loan_intent', 'previous_loan_defaults_on_file']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(cat_vars):\n",
    "    tasa = df.groupby(var)['loan_status'].mean() * 100\n",
    "    tasa.sort_values().plot(kind='barh', ax=axes[i], color='steelblue')\n",
    "    axes[i].set_title(f'Tasa de Aprobación por {var}', fontweight='bold')\n",
    "    axes[i].set_xlabel('% Aprobados')\n",
    "    axes[i].axvline(x=22.2, color='red', linestyle='--', label='Promedio general')\n",
    "\n",
    "axes[5].axis('off')  # Ocultar el 6to subplot vacío\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HALLAZGO CRÍTICO: Defaults previos\n",
    "print(\"=\"*60)\n",
    "print(\"HALLAZGO CRÍTICO: DEFAULTS PREVIOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for default in df['previous_loan_defaults_on_file'].unique():\n",
    "    subset = df[df['previous_loan_defaults_on_file'] == default]\n",
    "    tasa = subset['loan_status'].mean() * 100\n",
    "    print(f\"\\nDefaults previos = {default}:\")\n",
    "    print(f\"   Total: {len(subset):,} solicitudes\")\n",
    "    print(f\"   Tasa de aprobación: {tasa:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"⚠ CONCLUSIÓN: Si el solicitante tiene defaults previos,\")\n",
    "print(\"  la probabilidad de aprobación es 0%. Este es el factor\")\n",
    "print(\"  más determinante en la decisión de crédito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "num_cols = ['person_age', 'person_income', 'person_emp_exp', 'loan_amnt',\n",
    "            'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n",
    "            'credit_score', 'loan_status']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "corr_matrix = df[num_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, fmt='.2f', ax=ax)\n",
    "ax.set_title('Matriz de Correlación', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelaciones con loan_status:\")\n",
    "corr_target = corr_matrix['loan_status'].drop('loan_status').sort_values(key=abs, ascending=False)\n",
    "for var, corr in corr_target.items():\n",
    "    print(f\"   {var:30}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. Preprocesamiento con Pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir features y target\n",
    "features_num = ['person_age', 'person_income', 'person_emp_exp', 'loan_amnt',\n",
    "                'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n",
    "                'credit_score']\n",
    "\n",
    "features_cat = ['person_gender', 'person_education', 'person_home_ownership',\n",
    "                'loan_intent', 'previous_loan_defaults_on_file']\n",
    "\n",
    "X = df[features_num + features_cat]\n",
    "y = df['loan_status']\n",
    "\n",
    "print(f\"Features numéricas: {len(features_num)}\")\n",
    "print(f\"Features categóricas: {len(features_cat)}\")\n",
    "print(f\"Total features: {len(features_num) + len(features_cat)}\")\n",
    "print(f\"Muestras: {len(X):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos (estratificada para mantener proporción de clases)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DIVISIÓN DE DATOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nEntrenamiento: {len(X_train):,} muestras (80%)\")\n",
    "print(f\"Prueba: {len(X_test):,} muestras (20%)\")\n",
    "print(f\"\\nDistribución en entrenamiento:\")\n",
    "print(f\"   Clase 0: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "print(f\"   Clase 1: {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.1f}%)\")\n",
    "print(f\"\\nDistribución en prueba:\")\n",
    "print(f\"   Clase 0: {(y_test == 0).sum():,} ({(y_test == 0).mean()*100:.1f}%)\")\n",
    "print(f\"   Clase 1: {(y_test == 1).sum():,} ({(y_test == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Pipeline de preprocesamiento\n",
    "print(\"=\"*60)\n",
    "print(\"PIPELINE DE PREPROCESAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Preprocesador para variables numéricas\n",
    "preprocessor_num = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocesador para variables categóricas\n",
    "preprocessor_cat = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combinar preprocesadores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessor_num, features_num),\n",
    "        ('cat', preprocessor_cat, features_cat)\n",
    "    ])\n",
    "\n",
    "print(\"\"\"\n",
    "Estructura del Pipeline:\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    PIPELINE COMPLETO                        │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  ┌─────────────────────┐   ┌─────────────────────┐         │\n",
    "│  │ Variables Numéricas │   │ Variables Categóricas│        │\n",
    "│  │  (8 features)       │   │  (5 features)        │        │\n",
    "│  └──────────┬──────────┘   └──────────┬──────────┘         │\n",
    "│             │                         │                     │\n",
    "│             ▼                         ▼                     │\n",
    "│  ┌─────────────────────┐   ┌─────────────────────┐         │\n",
    "│  │ SimpleImputer       │   │ SimpleImputer       │         │\n",
    "│  │ (strategy='median') │   │ (strategy='mode')   │         │\n",
    "│  └──────────┬──────────┘   └──────────┬──────────┘         │\n",
    "│             │                         │                     │\n",
    "│             ▼                         ▼                     │\n",
    "│  ┌─────────────────────┐   ┌─────────────────────┐         │\n",
    "│  │ StandardScaler      │   │ OneHotEncoder       │         │\n",
    "│  │ (μ=0, σ=1)         │   │                     │         │\n",
    "│  └──────────┬──────────┘   └──────────┬──────────┘         │\n",
    "│             │                         │                     │\n",
    "│             └───────────┬─────────────┘                     │\n",
    "│                         │                                   │\n",
    "│                         ▼                                   │\n",
    "│              ┌─────────────────────┐                        │\n",
    "│              │    CLASIFICADOR     │                        │\n",
    "│              │  (Random Forest,    │                        │\n",
    "│              │   Logistic Reg, etc)│                        │\n",
    "│              └─────────────────────┘                        │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. Entrenamiento y Evaluación de Modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos\n",
    "modelos = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar\n",
    "resultados = []\n",
    "pipelines_entrenados = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENTRENAMIENTO Y EVALUACIÓN DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando {nombre}...\")\n",
    "    \n",
    "    # Crear pipeline completo\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', modelo)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    pipelines_entrenados[nombre] = pipeline\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Probabilidades (si están disponibles)\n",
    "    if hasattr(modelo, 'predict_proba'):\n",
    "        y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        auc = 0\n",
    "    \n",
    "    # Calcular métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': auc\n",
    "    })\n",
    "    \n",
    "    print(f\"   Accuracy:  {acc:.4f}\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall:    {rec:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "    print(f\"   AUC-ROC:   {auc:.4f}\")\n",
    "\n",
    "# Tabla de resultados\n",
    "df_resultados = pd.DataFrame(resultados).sort_values('F1-Score', ascending=False)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN DE RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "print(df_resultados.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización comparativa\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico de barras\n",
    "metricas = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "x = np.arange(len(metricas))\n",
    "width = 0.2\n",
    "\n",
    "for i, (_, row) in enumerate(df_resultados.iterrows()):\n",
    "    valores = [row['Accuracy'], row['Precision'], row['Recall'], row['F1-Score'], row['AUC-ROC']]\n",
    "    axes[0].bar(x + i*width, valores, width, label=row['Modelo'])\n",
    "\n",
    "axes[0].set_xlabel('Métrica')\n",
    "axes[0].set_ylabel('Valor')\n",
    "axes[0].set_title('Comparación de Métricas por Modelo', fontweight='bold')\n",
    "axes[0].set_xticks(x + width * 1.5)\n",
    "axes[0].set_xticklabels(metricas, rotation=45)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Curvas ROC\n",
    "for nombre, pipeline in pipelines_entrenados.items():\n",
    "    if hasattr(pipeline.named_steps['classifier'], 'predict_proba'):\n",
    "        y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        axes[1].plot(fpr, tpr, label=f'{nombre} (AUC={auc:.3f})')\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Aleatorio')\n",
    "axes[1].set_xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "axes[1].set_ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "axes[1].set_title('Curvas ROC', fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. Análisis Detallado del Mejor Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar mejor modelo\n",
    "mejor_nombre = df_resultados.iloc[0]['Modelo']\n",
    "mejor_pipeline = pipelines_entrenados[mejor_nombre]\n",
    "\n",
    "print(f\"MEJOR MODELO: {mejor_nombre}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = mejor_pipeline.predict(X_test)\n",
    "y_proba = mejor_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nREPORTE DE CLASIFICACIÓN\")\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Rechazado (0)', 'Aprobado (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz absoluta\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Rechazado', 'Aprobado'], \n",
    "            yticklabels=['Rechazado', 'Aprobado'], ax=axes[0])\n",
    "axes[0].set_title(f'Matriz de Confusión - {mejor_nombre}', fontweight='bold')\n",
    "axes[0].set_xlabel('Predicción')\n",
    "axes[0].set_ylabel('Valor Real')\n",
    "\n",
    "# Matriz normalizada\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=['Rechazado', 'Aprobado'], \n",
    "            yticklabels=['Rechazado', 'Aprobado'], ax=axes[1])\n",
    "axes[1].set_title('Matriz de Confusión Normalizada', fontweight='bold')\n",
    "axes[1].set_xlabel('Predicción')\n",
    "axes[1].set_ylabel('Valor Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretación\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nINTERPRETACIÓN DE LA MATRIZ DE CONFUSIÓN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nVerdaderos Negativos (TN): {tn:,}\")\n",
    "print(f\"   → Préstamos correctamente rechazados (habrían hecho default)\")\n",
    "print(f\"\\nFalsos Positivos (FP): {fp:,}\")\n",
    "print(f\"   → Préstamos aprobados incorrectamente (PÉRDIDA PARA EL BANCO)\")\n",
    "print(f\"\\nFalsos Negativos (FN): {fn:,}\")\n",
    "print(f\"   → Préstamos rechazados incorrectamente (OPORTUNIDAD PERDIDA)\")\n",
    "print(f\"\\nVerdaderos Positivos (TP): {tp:,}\")\n",
    "print(f\"   → Préstamos correctamente aprobados (clientes que pagan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicación de métricas\n",
    "print(\"=\"*70)\n",
    "print(\"EXPLICACIÓN DE MÉTRICAS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│ ACCURACY (Exactitud)                                                │\n",
    "│ ─────────────────────                                               │\n",
    "│ Fórmula: (TP + TN) / Total                                         │\n",
    "│ Interpretación: % de predicciones correctas                         │\n",
    "│                                                                     │\n",
    "│ ⚠ CUIDADO: En datasets desbalanceados puede ser engañosa.          │\n",
    "│   Un modelo que siempre prediga \"Rechazado\" tendría 77.8% accuracy │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│ PRECISION                                                           │\n",
    "│ ─────────                                                           │\n",
    "│ Fórmula: TP / (TP + FP)                                            │\n",
    "│ Pregunta: De los préstamos que APROBAMOS, ¿cuántos pagan?          │\n",
    "│                                                                     │\n",
    "│ Alta Precision = Pocos préstamos malos aprobados                   │\n",
    "│ Importante cuando: El costo de aprobar un mal préstamo es alto     │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│ RECALL (Sensibilidad)                                               │\n",
    "│ ─────────────────────                                               │\n",
    "│ Fórmula: TP / (TP + FN)                                            │\n",
    "│ Pregunta: De los buenos clientes, ¿a cuántos aprobamos?            │\n",
    "│                                                                     │\n",
    "│ Alto Recall = Pocos buenos clientes rechazados                     │\n",
    "│ Importante cuando: Perder buenos clientes tiene alto costo         │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│ F1-SCORE                                                            │\n",
    "│ ────────                                                            │\n",
    "│ Fórmula: 2 × (Precision × Recall) / (Precision + Recall)           │\n",
    "│ Interpretación: Balance entre Precision y Recall                   │\n",
    "│                                                                     │\n",
    "│ Útil cuando: Las clases están desbalanceadas                       │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│ AUC-ROC                                                             │\n",
    "│ ───────                                                             │\n",
    "│ Área bajo la curva ROC (0.5 = aleatorio, 1.0 = perfecto)           │\n",
    "│ Mide la capacidad de distinguir entre clases                       │\n",
    "│                                                                     │\n",
    "│ AUC > 0.9 = Excelente discriminación                               │\n",
    "│ AUC 0.8-0.9 = Buena discriminación                                 │\n",
    "│ AUC 0.7-0.8 = Aceptable                                            │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "# Métricas del mejor modelo\n",
    "print(f\"\\nMÉTRICAS DEL MODELO {mejor_nombre.upper()}:\")\n",
    "print(f\"   Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   AUC-ROC:   {roc_auc_score(y_test, y_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **7. Importancia de Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancia de variables\n",
    "if mejor_nombre in ['Random Forest', 'Gradient Boosting']:\n",
    "    importancia = mejor_pipeline.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Obtener nombres de features\n",
    "    cat_encoder = mejor_pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "    cat_feature_names = cat_encoder.named_steps['onehot'].get_feature_names_out(features_cat)\n",
    "    all_features = features_num + list(cat_feature_names)\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    imp_df = pd.DataFrame({\n",
    "        'Variable': all_features,\n",
    "        'Importancia': importancia\n",
    "    }).sort_values('Importancia', ascending=True)\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(imp_df)))\n",
    "    ax.barh(imp_df['Variable'], imp_df['Importancia'], color=colors)\n",
    "    ax.set_xlabel('Importancia')\n",
    "    ax.set_title(f'Importancia de Variables - {mejor_nombre}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTOP 10 VARIABLES MÁS IMPORTANTES:\")\n",
    "    print(\"=\"*60)\n",
    "    for i, row in imp_df.tail(10).iloc[::-1].iterrows():\n",
    "        print(f\"   {row['Variable']:40}: {row['Importancia']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **8. Validación Cruzada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada estratificada\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN CRUZADA ESTRATIFICADA (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nLa validación cruzada evalúa el modelo en múltiples particiones\")\n",
    "print(\"de los datos para obtener una estimación más robusta del rendimiento.\\n\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = []\n",
    "for nombre, modelo in modelos.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', modelo)\n",
    "    ])\n",
    "    \n",
    "    # Calcular scores para múltiples métricas\n",
    "    acc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='f1')\n",
    "    \n",
    "    cv_results.append({\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy_mean': acc_scores.mean(),\n",
    "        'Accuracy_std': acc_scores.std(),\n",
    "        'F1_mean': f1_scores.mean(),\n",
    "        'F1_std': f1_scores.std()\n",
    "    })\n",
    "    \n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"   Accuracy: {acc_scores.mean():.4f} (+/- {acc_scores.std()*2:.4f})\")\n",
    "    print(f\"   F1-Score: {f1_scores.mean():.4f} (+/- {f1_scores.std()*2:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **9. Predicción de Nuevos Casos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de predicción para nuevos solicitantes\n",
    "print(\"=\"*60)\n",
    "print(\"PREDICCIÓN PARA NUEVOS SOLICITANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear casos de ejemplo\n",
    "nuevos_casos = pd.DataFrame({\n",
    "    'person_age': [25, 35, 45],\n",
    "    'person_gender': ['male', 'female', 'male'],\n",
    "    'person_education': ['Bachelor', 'Master', 'High School'],\n",
    "    'person_income': [50000, 85000, 40000],\n",
    "    'person_emp_exp': [2, 8, 15],\n",
    "    'person_home_ownership': ['RENT', 'MORTGAGE', 'OWN'],\n",
    "    'loan_amnt': [10000, 25000, 8000],\n",
    "    'loan_intent': ['EDUCATION', 'HOMEIMPROVEMENT', 'MEDICAL'],\n",
    "    'loan_int_rate': [12.5, 9.0, 15.0],\n",
    "    'loan_percent_income': [0.20, 0.29, 0.20],\n",
    "    'cb_person_cred_hist_length': [3, 10, 20],\n",
    "    'credit_score': [650, 720, 580],\n",
    "    'previous_loan_defaults_on_file': ['No', 'No', 'Yes']\n",
    "})\n",
    "\n",
    "print(\"\\nCasos a evaluar:\")\n",
    "print(nuevos_casos[['person_age', 'person_income', 'loan_amnt', 'credit_score', 'previous_loan_defaults_on_file']].to_string())\n",
    "\n",
    "# Predecir\n",
    "predicciones = mejor_pipeline.predict(nuevos_casos)\n",
    "probabilidades = mejor_pipeline.predict_proba(nuevos_casos)\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"RESULTADOS:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i in range(len(nuevos_casos)):\n",
    "    resultado = \"APROBADO\" if predicciones[i] == 1 else \"RECHAZADO\"\n",
    "    prob = probabilidades[i][1] * 100\n",
    "    print(f\"\\nSolicitante {i+1}:\")\n",
    "    print(f\"   Edad: {nuevos_casos.iloc[i]['person_age']}, Ingresos: ${nuevos_casos.iloc[i]['person_income']:,}\")\n",
    "    print(f\"   Monto solicitado: ${nuevos_casos.iloc[i]['loan_amnt']:,}\")\n",
    "    print(f\"   Credit Score: {nuevos_casos.iloc[i]['credit_score']}\")\n",
    "    print(f\"   Defaults previos: {nuevos_casos.iloc[i]['previous_loan_defaults_on_file']}\")\n",
    "    print(f\"   → Decisión: {resultado}\")\n",
    "    print(f\"   → Probabilidad de pago: {prob:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **10. Conclusiones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CONCLUSIONES DEL ANÁLISIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "1. CARACTERIZACIÓN DEL DATASET\n",
    "   ────────────────────────────\n",
    "   • 45,000 solicitudes de préstamo analizadas\n",
    "   • Dataset DESBALANCEADO: 77.8% rechazados, 22.2% aprobados\n",
    "   • 13 variables predictoras (8 numéricas, 5 categóricas)\n",
    "\n",
    "2. HALLAZGO CRÍTICO: DEFAULTS PREVIOS\n",
    "   ──────────────────────────────────\n",
    "   • Si el solicitante tiene defaults previos → 0% de aprobación\n",
    "   • Sin defaults previos → 45.2% de aprobación\n",
    "   • Esta es la variable más determinante en la decisión\n",
    "\n",
    "3. RENDIMIENTO DEL MEJOR MODELO ({mejor_nombre})\n",
    "   ──────────────────────────────────────────────\n",
    "   • Accuracy:  {accuracy_score(y_test, y_pred):.4f} ({accuracy_score(y_test, y_pred)*100:.1f}% de predicciones correctas)\n",
    "   • Precision: {precision_score(y_test, y_pred):.4f} (De los aprobados, {precision_score(y_test, y_pred)*100:.1f}% pagan)\n",
    "   • Recall:    {recall_score(y_test, y_pred):.4f} (Detectamos {recall_score(y_test, y_pred)*100:.1f}% de buenos clientes)\n",
    "   • F1-Score:  {f1_score(y_test, y_pred):.4f} (Balance precision-recall)\n",
    "   • AUC-ROC:   {roc_auc_score(y_test, y_proba):.4f} (Excelente capacidad discriminativa)\n",
    "\n",
    "4. VARIABLES MÁS IMPORTANTES\n",
    "   ─────────────────────────\n",
    "   • loan_int_rate (Tasa de interés)\n",
    "   • loan_percent_income (% del ingreso)\n",
    "   • previous_loan_defaults_on_file (Defaults previos)\n",
    "   • person_income (Ingresos)\n",
    "\n",
    "5. USO DE PIPELINES\n",
    "   ─────────────────\n",
    "   • Los Pipelines garantizan preprocesamiento consistente\n",
    "   • Evitan data leakage entre entrenamiento y prueba\n",
    "   • Facilitan la reproducibilidad y el despliegue\n",
    "\n",
    "6. MÉTRICAS DE EVALUACIÓN\n",
    "   ──────────────────────\n",
    "   • PRECISION: Importante para minimizar pérdidas (préstamos malos aprobados)\n",
    "   • RECALL: Importante para no perder buenos clientes\n",
    "   • En banca, suele priorizarse PRECISION para evitar defaults\n",
    "\n",
    "7. RECOMENDACIONES\n",
    "   ────────────────\n",
    "   • Rechazar automáticamente solicitantes con defaults previos\n",
    "   • Evaluar cuidadosamente préstamos con alto % del ingreso\n",
    "   • Considerar ajustar el umbral de decisión según apetito de riesgo\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FIN DEL ANÁLISIS\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
